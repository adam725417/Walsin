# coding: utf-8

"""
    WEX REST APIs

    Authentication methods - Basic Auth - JSON Web Token   - [POST /api/v1/usermgmt/login](#!/User/signinUser)   - [POST /api/v1/usermgmt/logout](#!/User/doLogout) - Python client sample [Download](/docs/wex-python-api.zip) 

    OpenAPI spec version: 12.0.2.417
    
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""


from __future__ import absolute_import

import sys
import os
import re

# python 2 and python 3 compatibility library
from six import iteritems

from ..configuration import Configuration
from ..api_client import ApiClient


class CrawlerApi(object):
    """
    NOTE: This class is auto generated by the swagger code generator program.
    Do not edit the class manually.
    Ref: https://github.com/swagger-api/swagger-codegen
    """

    def __init__(self, api_client=None):
        config = Configuration()
        if api_client:
            self.api_client = api_client
        else:
            if not config.api_client:
                config.api_client = ApiClient()
            self.api_client = config.api_client

    def create(self, dataset_id, **kwargs):
        """
        Create a crawler
        Create a crawler
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.create(dataset_id, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str dataset_id: (required)
        :param CrawlerConfiguration body:
        :return: Crawler
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('callback'):
            return self.create_with_http_info(dataset_id, **kwargs)
        else:
            (data) = self.create_with_http_info(dataset_id, **kwargs)
            return data

    def create_with_http_info(self, dataset_id, **kwargs):
        """
        Create a crawler
        Create a crawler
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.create_with_http_info(dataset_id, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str dataset_id: (required)
        :param CrawlerConfiguration body:
        :return: Crawler
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['dataset_id', 'body']
        all_params.append('callback')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method create" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'dataset_id' is set
        if ('dataset_id' not in params) or (params['dataset_id'] is None):
            raise ValueError("Missing the required parameter `dataset_id` when calling `create`")


        collection_formats = {}

        path_params = {}
        if 'dataset_id' in params:
            path_params['datasetId'] = params['dataset_id']

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        if 'body' in params:
            body_params = params['body']
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.\
            select_header_accept(['application/json'])

        # HTTP header `Content-Type`
        header_params['Content-Type'] = self.api_client.\
            select_header_content_type(['application/json'])

        # Authentication setting
        auth_settings = ['basicAuth']

        return self.api_client.call_api('/api/v1/datasets/{datasetId}/crawlers', 'POST',
                                        path_params,
                                        query_params,
                                        header_params,
                                        body=body_params,
                                        post_params=form_params,
                                        files=local_var_files,
                                        response_type='Crawler',
                                        auth_settings=auth_settings,
                                        callback=params.get('callback'),
                                        _return_http_data_only=params.get('_return_http_data_only'),
                                        _preload_content=params.get('_preload_content', True),
                                        _request_timeout=params.get('_request_timeout'),
                                        collection_formats=collection_formats)

    def delete(self, dataset_id, crawler_id, **kwargs):
        """
        Delete a crawler
        Delete a configuration of a specified crawler
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.delete(dataset_id, crawler_id, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str dataset_id: (required)
        :param str crawler_id: (required)
        :return: SimpleResponse
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('callback'):
            return self.delete_with_http_info(dataset_id, crawler_id, **kwargs)
        else:
            (data) = self.delete_with_http_info(dataset_id, crawler_id, **kwargs)
            return data

    def delete_with_http_info(self, dataset_id, crawler_id, **kwargs):
        """
        Delete a crawler
        Delete a configuration of a specified crawler
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.delete_with_http_info(dataset_id, crawler_id, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str dataset_id: (required)
        :param str crawler_id: (required)
        :return: SimpleResponse
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['dataset_id', 'crawler_id']
        all_params.append('callback')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method delete" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'dataset_id' is set
        if ('dataset_id' not in params) or (params['dataset_id'] is None):
            raise ValueError("Missing the required parameter `dataset_id` when calling `delete`")
        # verify the required parameter 'crawler_id' is set
        if ('crawler_id' not in params) or (params['crawler_id'] is None):
            raise ValueError("Missing the required parameter `crawler_id` when calling `delete`")


        collection_formats = {}

        path_params = {}
        if 'dataset_id' in params:
            path_params['datasetId'] = params['dataset_id']
        if 'crawler_id' in params:
            path_params['crawlerId'] = params['crawler_id']

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.\
            select_header_accept(['application/json'])

        # Authentication setting
        auth_settings = ['basicAuth']

        return self.api_client.call_api('/api/v1/datasets/{datasetId}/crawlers/{crawlerId}', 'DELETE',
                                        path_params,
                                        query_params,
                                        header_params,
                                        body=body_params,
                                        post_params=form_params,
                                        files=local_var_files,
                                        response_type='SimpleResponse',
                                        auth_settings=auth_settings,
                                        callback=params.get('callback'),
                                        _return_http_data_only=params.get('_return_http_data_only'),
                                        _preload_content=params.get('_preload_content', True),
                                        _request_timeout=params.get('_request_timeout'),
                                        collection_formats=collection_formats)

    def discover_subspaces(self, **kwargs):
        """
        Discover subspaces
        Discover subspaces available for the crawler with the provided path / filter.
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.discover_subspaces(callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str path:
        :param str filters:
        :param CrawlerConfiguration body:
        :return: ListDiscoveredSubspaces
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('callback'):
            return self.discover_subspaces_with_http_info(**kwargs)
        else:
            (data) = self.discover_subspaces_with_http_info(**kwargs)
            return data

    def discover_subspaces_with_http_info(self, **kwargs):
        """
        Discover subspaces
        Discover subspaces available for the crawler with the provided path / filter.
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.discover_subspaces_with_http_info(callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str path:
        :param str filters:
        :param CrawlerConfiguration body:
        :return: ListDiscoveredSubspaces
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['path', 'filters', 'body']
        all_params.append('callback')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method discover_subspaces" % key
                )
            params[key] = val
        del params['kwargs']


        collection_formats = {}

        path_params = {}

        query_params = []
        if 'path' in params:
            query_params.append(('path', params['path']))
        if 'filters' in params:
            query_params.append(('filters', params['filters']))

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        if 'body' in params:
            body_params = params['body']
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.\
            select_header_accept(['application/json'])

        # HTTP header `Content-Type`
        header_params['Content-Type'] = self.api_client.\
            select_header_content_type(['application/json'])

        # Authentication setting
        auth_settings = ['basicAuth']

        return self.api_client.call_api('/api/v1/crawler/subspaces', 'POST',
                                        path_params,
                                        query_params,
                                        header_params,
                                        body=body_params,
                                        post_params=form_params,
                                        files=local_var_files,
                                        response_type='ListDiscoveredSubspaces',
                                        auth_settings=auth_settings,
                                        callback=params.get('callback'),
                                        _return_http_data_only=params.get('_return_http_data_only'),
                                        _preload_content=params.get('_preload_content', True),
                                        _request_timeout=params.get('_request_timeout'),
                                        collection_formats=collection_formats)

    def get(self, dataset_id, crawler_id, **kwargs):
        """
        Get a crawler configuration
        Get a crawler configuration
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.get(dataset_id, crawler_id, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str dataset_id: (required)
        :param str crawler_id: (required)
        :return: CrawlerConfiguration
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('callback'):
            return self.get_with_http_info(dataset_id, crawler_id, **kwargs)
        else:
            (data) = self.get_with_http_info(dataset_id, crawler_id, **kwargs)
            return data

    def get_with_http_info(self, dataset_id, crawler_id, **kwargs):
        """
        Get a crawler configuration
        Get a crawler configuration
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.get_with_http_info(dataset_id, crawler_id, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str dataset_id: (required)
        :param str crawler_id: (required)
        :return: CrawlerConfiguration
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['dataset_id', 'crawler_id']
        all_params.append('callback')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method get" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'dataset_id' is set
        if ('dataset_id' not in params) or (params['dataset_id'] is None):
            raise ValueError("Missing the required parameter `dataset_id` when calling `get`")
        # verify the required parameter 'crawler_id' is set
        if ('crawler_id' not in params) or (params['crawler_id'] is None):
            raise ValueError("Missing the required parameter `crawler_id` when calling `get`")


        collection_formats = {}

        path_params = {}
        if 'dataset_id' in params:
            path_params['datasetId'] = params['dataset_id']
        if 'crawler_id' in params:
            path_params['crawlerId'] = params['crawler_id']

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.\
            select_header_accept(['application/json'])

        # Authentication setting
        auth_settings = ['basicAuth']

        return self.api_client.call_api('/api/v1/datasets/{datasetId}/crawlers/{crawlerId}', 'GET',
                                        path_params,
                                        query_params,
                                        header_params,
                                        body=body_params,
                                        post_params=form_params,
                                        files=local_var_files,
                                        response_type='CrawlerConfiguration',
                                        auth_settings=auth_settings,
                                        callback=params.get('callback'),
                                        _return_http_data_only=params.get('_return_http_data_only'),
                                        _preload_content=params.get('_preload_content', True),
                                        _request_timeout=params.get('_request_timeout'),
                                        collection_formats=collection_formats)

    def get_template(self, crawler_type_name, **kwargs):
        """
        Get a crawler template for a specified cralwer type
        Get a crawler template
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.get_template(crawler_type_name, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str crawler_type_name: (required)
        :return: ConfigurationTemplate
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('callback'):
            return self.get_template_with_http_info(crawler_type_name, **kwargs)
        else:
            (data) = self.get_template_with_http_info(crawler_type_name, **kwargs)
            return data

    def get_template_with_http_info(self, crawler_type_name, **kwargs):
        """
        Get a crawler template for a specified cralwer type
        Get a crawler template
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.get_template_with_http_info(crawler_type_name, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str crawler_type_name: (required)
        :return: ConfigurationTemplate
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['crawler_type_name']
        all_params.append('callback')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method get_template" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'crawler_type_name' is set
        if ('crawler_type_name' not in params) or (params['crawler_type_name'] is None):
            raise ValueError("Missing the required parameter `crawler_type_name` when calling `get_template`")


        collection_formats = {}

        path_params = {}
        if 'crawler_type_name' in params:
            path_params['crawlerTypeName'] = params['crawler_type_name']

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.\
            select_header_accept(['application/json'])

        # Authentication setting
        auth_settings = ['basicAuth']

        return self.api_client.call_api('/api/v1/crawler/types/{crawlerTypeName}', 'GET',
                                        path_params,
                                        query_params,
                                        header_params,
                                        body=body_params,
                                        post_params=form_params,
                                        files=local_var_files,
                                        response_type='ConfigurationTemplate',
                                        auth_settings=auth_settings,
                                        callback=params.get('callback'),
                                        _return_http_data_only=params.get('_return_http_data_only'),
                                        _preload_content=params.get('_preload_content', True),
                                        _request_timeout=params.get('_request_timeout'),
                                        collection_formats=collection_formats)

    def get_types(self, **kwargs):
        """
        Get a list of crawler types
        Get a list of available crawler types.
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.get_types(callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :return: ListResponseConfigurationType
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('callback'):
            return self.get_types_with_http_info(**kwargs)
        else:
            (data) = self.get_types_with_http_info(**kwargs)
            return data

    def get_types_with_http_info(self, **kwargs):
        """
        Get a list of crawler types
        Get a list of available crawler types.
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.get_types_with_http_info(callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :return: ListResponseConfigurationType
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = []
        all_params.append('callback')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method get_types" % key
                )
            params[key] = val
        del params['kwargs']

        collection_formats = {}

        path_params = {}

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.\
            select_header_accept(['application/json'])

        # Authentication setting
        auth_settings = ['basicAuth']

        return self.api_client.call_api('/api/v1/crawler/types', 'GET',
                                        path_params,
                                        query_params,
                                        header_params,
                                        body=body_params,
                                        post_params=form_params,
                                        files=local_var_files,
                                        response_type='ListResponseConfigurationType',
                                        auth_settings=auth_settings,
                                        callback=params.get('callback'),
                                        _return_http_data_only=params.get('_return_http_data_only'),
                                        _preload_content=params.get('_preload_content', True),
                                        _request_timeout=params.get('_request_timeout'),
                                        collection_formats=collection_formats)

    def list(self, dataset_id, **kwargs):
        """
        Get a list of crawlers
        Get a list of crawlers
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.list(dataset_id, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str dataset_id: (required)
        :return: ListResponseCrawler
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('callback'):
            return self.list_with_http_info(dataset_id, **kwargs)
        else:
            (data) = self.list_with_http_info(dataset_id, **kwargs)
            return data

    def list_with_http_info(self, dataset_id, **kwargs):
        """
        Get a list of crawlers
        Get a list of crawlers
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.list_with_http_info(dataset_id, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str dataset_id: (required)
        :return: ListResponseCrawler
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['dataset_id']
        all_params.append('callback')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method list" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'dataset_id' is set
        if ('dataset_id' not in params) or (params['dataset_id'] is None):
            raise ValueError("Missing the required parameter `dataset_id` when calling `list`")


        collection_formats = {}

        path_params = {}
        if 'dataset_id' in params:
            path_params['datasetId'] = params['dataset_id']

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.\
            select_header_accept(['application/json'])

        # Authentication setting
        auth_settings = ['basicAuth']

        return self.api_client.call_api('/api/v1/datasets/{datasetId}/crawlers', 'GET',
                                        path_params,
                                        query_params,
                                        header_params,
                                        body=body_params,
                                        post_params=form_params,
                                        files=local_var_files,
                                        response_type='ListResponseCrawler',
                                        auth_settings=auth_settings,
                                        callback=params.get('callback'),
                                        _return_http_data_only=params.get('_return_http_data_only'),
                                        _preload_content=params.get('_preload_content', True),
                                        _request_timeout=params.get('_request_timeout'),
                                        collection_formats=collection_formats)

    def start(self, dataset_id, crawler_id, **kwargs):
        """
        Start a crawler
        Starts ingesting documents with a crawler.
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.start(dataset_id, crawler_id, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str dataset_id: The ID of the dataset. (required)
        :param str crawler_id: The ID of the crawler. (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('callback'):
            return self.start_with_http_info(dataset_id, crawler_id, **kwargs)
        else:
            (data) = self.start_with_http_info(dataset_id, crawler_id, **kwargs)
            return data

    def start_with_http_info(self, dataset_id, crawler_id, **kwargs):
        """
        Start a crawler
        Starts ingesting documents with a crawler.
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.start_with_http_info(dataset_id, crawler_id, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str dataset_id: The ID of the dataset. (required)
        :param str crawler_id: The ID of the crawler. (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['dataset_id', 'crawler_id']
        all_params.append('callback')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method start" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'dataset_id' is set
        if ('dataset_id' not in params) or (params['dataset_id'] is None):
            raise ValueError("Missing the required parameter `dataset_id` when calling `start`")
        # verify the required parameter 'crawler_id' is set
        if ('crawler_id' not in params) or (params['crawler_id'] is None):
            raise ValueError("Missing the required parameter `crawler_id` when calling `start`")


        collection_formats = {}

        path_params = {}
        if 'dataset_id' in params:
            path_params['datasetId'] = params['dataset_id']
        if 'crawler_id' in params:
            path_params['crawlerId'] = params['crawler_id']

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.\
            select_header_accept(['application/json'])

        # Authentication setting
        auth_settings = ['basicAuth']

        return self.api_client.call_api('/api/v1/datasets/{datasetId}/crawlers/{crawlerId}/start', 'POST',
                                        path_params,
                                        query_params,
                                        header_params,
                                        body=body_params,
                                        post_params=form_params,
                                        files=local_var_files,
                                        response_type=None,
                                        auth_settings=auth_settings,
                                        callback=params.get('callback'),
                                        _return_http_data_only=params.get('_return_http_data_only'),
                                        _preload_content=params.get('_preload_content', True),
                                        _request_timeout=params.get('_request_timeout'),
                                        collection_formats=collection_formats)

    def status(self, dataset_id, crawler_id, **kwargs):
        """
        List crawler status
        Displays status information about a crawler.
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.status(dataset_id, crawler_id, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str dataset_id: The ID of the dataset. (required)
        :param str crawler_id: The ID of the crawler. (required)
        :return: ZkIngestionStatus
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('callback'):
            return self.status_with_http_info(dataset_id, crawler_id, **kwargs)
        else:
            (data) = self.status_with_http_info(dataset_id, crawler_id, **kwargs)
            return data

    def status_with_http_info(self, dataset_id, crawler_id, **kwargs):
        """
        List crawler status
        Displays status information about a crawler.
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.status_with_http_info(dataset_id, crawler_id, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str dataset_id: The ID of the dataset. (required)
        :param str crawler_id: The ID of the crawler. (required)
        :return: ZkIngestionStatus
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['dataset_id', 'crawler_id']
        all_params.append('callback')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method status" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'dataset_id' is set
        if ('dataset_id' not in params) or (params['dataset_id'] is None):
            raise ValueError("Missing the required parameter `dataset_id` when calling `status`")
        # verify the required parameter 'crawler_id' is set
        if ('crawler_id' not in params) or (params['crawler_id'] is None):
            raise ValueError("Missing the required parameter `crawler_id` when calling `status`")


        collection_formats = {}

        path_params = {}
        if 'dataset_id' in params:
            path_params['datasetId'] = params['dataset_id']
        if 'crawler_id' in params:
            path_params['crawlerId'] = params['crawler_id']

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.\
            select_header_accept(['application/json'])

        # Authentication setting
        auth_settings = ['basicAuth']

        return self.api_client.call_api('/api/v1/datasets/{datasetId}/crawlers/{crawlerId}/status', 'GET',
                                        path_params,
                                        query_params,
                                        header_params,
                                        body=body_params,
                                        post_params=form_params,
                                        files=local_var_files,
                                        response_type='ZkIngestionStatus',
                                        auth_settings=auth_settings,
                                        callback=params.get('callback'),
                                        _return_http_data_only=params.get('_return_http_data_only'),
                                        _preload_content=params.get('_preload_content', True),
                                        _request_timeout=params.get('_request_timeout'),
                                        collection_formats=collection_formats)

    def stop(self, dataset_id, crawler_id, **kwargs):
        """
        Stop a crawler
        Stops ingesting documents with a crawler.
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.stop(dataset_id, crawler_id, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str dataset_id: The ID of the dataset. (required)
        :param str crawler_id: The ID of the crawler. (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('callback'):
            return self.stop_with_http_info(dataset_id, crawler_id, **kwargs)
        else:
            (data) = self.stop_with_http_info(dataset_id, crawler_id, **kwargs)
            return data

    def stop_with_http_info(self, dataset_id, crawler_id, **kwargs):
        """
        Stop a crawler
        Stops ingesting documents with a crawler.
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.stop_with_http_info(dataset_id, crawler_id, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str dataset_id: The ID of the dataset. (required)
        :param str crawler_id: The ID of the crawler. (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['dataset_id', 'crawler_id']
        all_params.append('callback')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method stop" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'dataset_id' is set
        if ('dataset_id' not in params) or (params['dataset_id'] is None):
            raise ValueError("Missing the required parameter `dataset_id` when calling `stop`")
        # verify the required parameter 'crawler_id' is set
        if ('crawler_id' not in params) or (params['crawler_id'] is None):
            raise ValueError("Missing the required parameter `crawler_id` when calling `stop`")


        collection_formats = {}

        path_params = {}
        if 'dataset_id' in params:
            path_params['datasetId'] = params['dataset_id']
        if 'crawler_id' in params:
            path_params['crawlerId'] = params['crawler_id']

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.\
            select_header_accept(['application/json'])

        # Authentication setting
        auth_settings = ['basicAuth']

        return self.api_client.call_api('/api/v1/datasets/{datasetId}/crawlers/{crawlerId}/stop', 'POST',
                                        path_params,
                                        query_params,
                                        header_params,
                                        body=body_params,
                                        post_params=form_params,
                                        files=local_var_files,
                                        response_type=None,
                                        auth_settings=auth_settings,
                                        callback=params.get('callback'),
                                        _return_http_data_only=params.get('_return_http_data_only'),
                                        _preload_content=params.get('_preload_content', True),
                                        _request_timeout=params.get('_request_timeout'),
                                        collection_formats=collection_formats)

    def update(self, dataset_id, crawler_id, **kwargs):
        """
        Update a crawler configuration
        Update a configuration of a specified crawler
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.update(dataset_id, crawler_id, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str dataset_id: (required)
        :param str crawler_id: (required)
        :param CrawlerConfiguration body:
        :return: Crawler
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('callback'):
            return self.update_with_http_info(dataset_id, crawler_id, **kwargs)
        else:
            (data) = self.update_with_http_info(dataset_id, crawler_id, **kwargs)
            return data

    def update_with_http_info(self, dataset_id, crawler_id, **kwargs):
        """
        Update a crawler configuration
        Update a configuration of a specified crawler
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please define a `callback` function
        to be invoked when receiving the response.
        >>> def callback_function(response):
        >>>     pprint(response)
        >>>
        >>> thread = api.update_with_http_info(dataset_id, crawler_id, callback=callback_function)

        :param callback function: The callback function
            for asynchronous request. (optional)
        :param str dataset_id: (required)
        :param str crawler_id: (required)
        :param CrawlerConfiguration body:
        :return: Crawler
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['dataset_id', 'crawler_id', 'body']
        all_params.append('callback')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method update" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'dataset_id' is set
        if ('dataset_id' not in params) or (params['dataset_id'] is None):
            raise ValueError("Missing the required parameter `dataset_id` when calling `update`")
        # verify the required parameter 'crawler_id' is set
        if ('crawler_id' not in params) or (params['crawler_id'] is None):
            raise ValueError("Missing the required parameter `crawler_id` when calling `update`")


        collection_formats = {}

        path_params = {}
        if 'dataset_id' in params:
            path_params['datasetId'] = params['dataset_id']
        if 'crawler_id' in params:
            path_params['crawlerId'] = params['crawler_id']

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        if 'body' in params:
            body_params = params['body']
        # HTTP header `Content-Type`
        header_params['Content-Type'] = self.api_client.\
            select_header_content_type(['application/json'])

        # Authentication setting
        auth_settings = ['basicAuth']

        return self.api_client.call_api('/api/v1/datasets/{datasetId}/crawlers/{crawlerId}', 'PUT',
                                        path_params,
                                        query_params,
                                        header_params,
                                        body=body_params,
                                        post_params=form_params,
                                        files=local_var_files,
                                        response_type='Crawler',
                                        auth_settings=auth_settings,
                                        callback=params.get('callback'),
                                        _return_http_data_only=params.get('_return_http_data_only'),
                                        _preload_content=params.get('_preload_content', True),
                                        _request_timeout=params.get('_request_timeout'),
                                        collection_formats=collection_formats)
